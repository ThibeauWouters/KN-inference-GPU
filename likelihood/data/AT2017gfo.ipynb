{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to explore the potential use of GPU for AT2017gfo PE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: first have to figure out the likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if CUDA is found:\n",
      "[cuda(id=0)]\n"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import arviz\n",
    "import time\n",
    "import copy\n",
    "import inspect \n",
    "from jax.scipy.stats import truncnorm\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "# matlotlib settings\n",
    "params = {\"axes.grid\": True,\n",
    "        \"text.usetex\" : False, # TODO enable latex, but this breaks if filters have underscore\n",
    "        \"font.family\" : \"serif\",\n",
    "        \"ytick.color\" : \"black\",\n",
    "        \"xtick.color\" : \"black\",\n",
    "        \"axes.labelcolor\" : \"black\",\n",
    "        \"axes.edgecolor\" : \"black\",\n",
    "        \"font.serif\" : [\"Computer Modern Serif\"],\n",
    "        \"xtick.labelsize\": 16,\n",
    "        \"ytick.labelsize\": 16,\n",
    "        \"axes.labelsize\": 16,\n",
    "        \"legend.fontsize\": 16,\n",
    "        \"legend.title_fontsize\": 16,\n",
    "        \"figure.titlesize\": 16}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "# NMMA imports\n",
    "import nmma as nmma\n",
    "from nmma.em.io import loadEvent\n",
    "from nmma.em.model import SVDLightCurveModel\n",
    "from nmma.em.utils import get_calc_lc_jit\n",
    "from nmma.em.io import read_photometry_files\n",
    "from nmma.em.utils import interpolate_nans\n",
    "import nmma.em.model_parameters as model_parameters\n",
    "\n",
    "MODEL_FUNCTIONS = {\n",
    "    k: v for k, v in model_parameters.__dict__.items() if inspect.isfunction(v)\n",
    "}\n",
    "model_name = \"Bu2022Ye\"\n",
    "model_function = MODEL_FUNCTIONS[model_name]\n",
    "\n",
    "# flowMC imports\n",
    "from flowMC.nfmodel.rqSpline import MaskedCouplingRQSpline\n",
    "from flowMC.sampler.Gaussian_random_walk import GaussianRandomWalk\n",
    "from flowMC.sampler.MALA import MALA\n",
    "from flowMC.sampler.Sampler import Sampler\n",
    "from flowMC.utils.PRNG_keys import initialize_rng_keys\n",
    "from flowMC.nfmodel.utils import *\n",
    "\n",
    "# jax imports\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "jax.config.update(\"jax_debug_nans\", False)\n",
    "import jaxlib\n",
    "import jax.numpy as jnp\n",
    "print(\"Checking if CUDA is found:\")\n",
    "print(jax.devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data\n",
    "\n",
    "**TODO**: for now, I am ignoring non inf datapoints for simplicity. Have to extend to include inf datapoints as well.\n",
    "\n",
    "**TODO**: Not sure if t can also be just the times we want to have, i.e., the times of the datapoints? Can reduce memory and improve efficiency>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filters:\n",
      "['ps1__g', 'ps1__r', 'ps1__i', 'ps1__z', 'ps1__y', '2massj', '2massh', '2massks', 'sdssu']\n"
     ]
    }
   ],
   "source": [
    "data_file = \"../data/AT2017gfo_no_inf.dat\"\n",
    "trigger_time = 57982.5285236896\n",
    "tmin, tmax = 0.05, 14\n",
    "data = loadEvent(data_file)\n",
    "# Read the LC dataset and interpolate the NaNs, and get training data\n",
    "# lcs_dir = \"/home/urash/twouters/KN_Lightcurves/lightcurves/bulla_2022\" # for remote SSH Potsdam\n",
    "# filenames = os.listdir(lcs_dir)\n",
    "# full_filenames = [os.path.join(lcs_dir, f) for f in filenames]\n",
    "# lc_dataset = read_photometry_files(full_filenames)\n",
    "# lc_dataset = interpolate_nans(lc_dataset)\n",
    "# training_data, parameters = model_function(lc_dataset)\n",
    "filters = list(data.keys())\n",
    "print(\"Filters:\")\n",
    "print(filters)\n",
    "\n",
    "sample_times = jnp.linspace(tmin, tmax, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    }
   ],
   "source": [
    "### Plot hyperparameters\n",
    "set_ylim = True\n",
    "set_yticks = True\n",
    "show_legend = False\n",
    "show_data = False\n",
    "\n",
    "error_budget = '1.0'\n",
    "error_budget = [float(x) for x in error_budget.split(\",\")]\n",
    "error_budget = dict(zip(filters, error_budget * len(filters)))\n",
    "xlim = f\"{tmin},{tmax}\"\n",
    "ylim = \"32, 15\"\n",
    "x_left = 3e-1\n",
    "x_right = tmax + 3\n",
    "\n",
    "# colors = cm.Spectral(np.linspace(0, 1, len(filters)))[::-1]\n",
    "\n",
    "plt.figure(figsize=(14, 34))\n",
    "\n",
    "cnt = 0\n",
    "for filt in filters:\n",
    "    cnt = cnt + 1\n",
    "    if cnt == 1:\n",
    "        ax1 = plt.subplot(len(filters), 1, cnt)\n",
    "    elif cnt == 2 or cnt == 3:\n",
    "        ax2 = plt.subplot(len(filters), 1, cnt, sharex=ax1)\n",
    "    else:\n",
    "        ax2 = plt.subplot(len(filters), 1, cnt, sharex=ax1)\n",
    "\n",
    "    samples = data[filt]\n",
    "    t, y, sigma_y = copy.deepcopy(samples[:, 0]), copy.deepcopy(samples[:, 1]), copy.deepcopy(samples[:, 2])\n",
    "    t -= trigger_time   \n",
    "    idx = np.where(~np.isnan(y))[0]\n",
    "    t, y, sigma_y = t[idx], y[idx], sigma_y[idx]\n",
    "\n",
    "    # 1) plot data points\n",
    "    idx = np.where(np.isfinite(sigma_y))[0]\n",
    "    plt.errorbar(t[idx], y[idx], sigma_y[idx], fmt=\"o\", color='k', markersize=10, capsize=10)\n",
    "    # plot upper bounds\n",
    "    idx = np.where(~np.isfinite(sigma_y))[0]\n",
    "    plt.errorbar(t[idx], y[idx], sigma_y[idx], fmt=\"v\", color='k', markersize=10, capsize=10)\n",
    "\n",
    "    #plt.ylim([float(x) for x in ylim.split(\",\")])\n",
    "    plt.xlim([float(x) for x in xlim.split(\",\")])\n",
    "    plt.xscale('log')\n",
    "    plt.grid()\n",
    "    \n",
    "    filt_label = filt\n",
    "    \n",
    "    if cnt == 1:\n",
    "        \n",
    "        plt.ylabel(filt_label, rotation=90, labelpad=15)\n",
    "        if set_ylim:\n",
    "            ax1.set_ylim([30,15])\n",
    "        #plt.ylim([float(x) for x in ylim.split(\",\")])\n",
    "    else:\n",
    "        # filt_label = filt.replace(\"__\", \"-\")\n",
    "        plt.ylabel(filt_label, rotation=90, labelpad=15)\n",
    "        if set_ylim:\n",
    "            ax2.set_ylim([30,15])\n",
    "        #plt.ylim([float(x) for x in ylim.split(\",\")])\n",
    "\n",
    "    if cnt == 1:\n",
    "        if set_yticks:\n",
    "            ax1.set_yticks([30, 25, 20, 15])\n",
    "        else:\n",
    "            ax1.invert_yaxis()\n",
    "        ax1.set_xlim(left=x_left, right=x_right)\n",
    "        plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "        legend = plt.legend(loc = \"center\", bbox_to_anchor=(0.5, 1.2), shadow=False,\n",
    "                            fancybox=True, ncol=4)\n",
    "        legend.get_frame().set_alpha(None)\n",
    "    else:\n",
    "        if set_yticks:\n",
    "            ax2.set_yticks([30, 25, 20, 15])\n",
    "        else:\n",
    "            ax2.invert_yaxis()\n",
    "        ax2.set_xlim(left=x_left, right=x_right)\n",
    "    \n",
    "\n",
    "ax1.set_zorder(1)\n",
    "plt.xlabel(\"Time [days]\")\n",
    "ax2.tick_params(axis='x', which='major', pad=15)\n",
    "#plt.legend(bbox_to_anchor=(0., 12.9, 1.025, .0), ncol=2, fontsize=40, frameon=True)\n",
    "#plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.2, wspace=0)\n",
    "\n",
    "if not show_legend:\n",
    "    legend.remove()\n",
    "\n",
    "if show_data:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/urash/twouters/nmma_models/flax_models/Bu2022Ye.pkl\n"
     ]
    }
   ],
   "source": [
    "svd_path = \"/home/urash/twouters/nmma_models/flax_models/\"\n",
    "\n",
    "lc_model = SVDLightCurveModel(\n",
    "        model_name,\n",
    "        t,\n",
    "        svd_path=svd_path,\n",
    "        parameter_conversion=None,\n",
    "        mag_ncoeff=10,\n",
    "        lbol_ncoeff=None,\n",
    "        interpolation_type=\"flax\",\n",
    "        model_parameters=None,\n",
    "        filters=filters,\n",
    "        local_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate light curves with jit:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: sample times must be the same here as within the log-likelihood call, it cannot be changed for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nmma.em.utils import calc_lc_flax\n",
    "\n",
    "calc_lc_given_params = lambda x: calc_lc_flax(sample_times, x, svd_mag_model=lc_model.svd_mag_model, svd_lbol_model=None, mag_ncoeff=10, lbol_ncoeff=None, filters=filters)\n",
    "\n",
    "## Using the NMMA function\n",
    "# calc_lc_given_params_jit = get_calc_lc_jit(sample_times, svd_mag_model=lc_model.svd_mag_model, filters=filters)\n",
    "\n",
    "## Jitting myself here:\n",
    "calc_lc_given_params_jit = jax.jit(calc_lc_given_params)\n",
    "\n",
    "# test it:\n",
    "test_params = jnp.array([-2.30103, 0.12, 0.3, -1.30103, 0.03, 25.84])\n",
    "_, _, test_lc = calc_lc_given_params_jit(test_params)\n",
    "# TODO is this correct?\n",
    "# Convert from jax numpy to just numpy\n",
    "test_lc_np = {f: np.asarray(test_lc[f]) for f in filters}\n",
    "\n",
    "# test_lc_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with flowMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at `/home/urash/twouters/gpu_projects/KN_inference/cpu/priors/AT2017gfo_Bu2022Ye_uniform_iota.prior`:\n",
    "```markdown\n",
    "luminosity_distance = 44\n",
    "inclination_EM = Uniform(name='inclination_EM', minimum=0., maximum=np.pi/2., latex_label='$\\\\iota$')\n",
    "log10_mej_dyn  = Uniform(name='log10_mej_dyn', minimum=-3, maximum=-1.7, latex_label='$\\\\log_{10}M^{\\\\rm{dyn}}_{\\\\rm{ej}}$')\n",
    "vej_dyn = Uniform(name='vej_dyn', minimum=0.12, maximum=0.25, latex_label='$V^{\\\\rm{dyn}}_{\\\\rm{ej}}$')\n",
    "Yedyn = Uniform(name='Yedyn', minimum=0.15, maximum=0.3, latex_label='$Y_{\\\\rm{e}}$')\n",
    "log10_mej_wind = Uniform(name='log10_mej_wind', minimum=-2, maximum=-0.89, latex_label='$\\\\log_{10}M^{\\\\rm{wind}}_{\\\\rm{ej}}$')\n",
    "vej_wind = Uniform(name='vej_wind', minimum=0.03, maximum=0.15, latex_label='$V^{\\\\rm{wind}}_{\\\\rm{ej}}$')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['log10_mej_dyn', 'vej_dyn', 'Yedyn', 'log10_mej_wind', 'vej_wind', 'KNtheta']\n"
     ]
    }
   ],
   "source": [
    "parameters = ['log10_mej_dyn', 'vej_dyn', 'Yedyn', 'log10_mej_wind', 'vej_wind', 'KNtheta']\n",
    "prior_range = jnp.array([[-3, 1.7], [0.12, 0.25], [0.15, 0.3], [-2, 0.89], [-2, -0.89], [0, jnp.pi / 2]])\n",
    "n_dim = len(prior_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_hat(x):\n",
    "    output = 0.\n",
    "    for i in range(n_dim):\n",
    "        output = jax.lax.cond(x[i]>=prior_range[i,0], lambda: output, lambda: -jnp.inf)\n",
    "        output = jax.lax.cond(x[i]<=prior_range[i,1], lambda: output, lambda: -jnp.inf)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_gaussian(m_det, m_err, m_est, lim):\n",
    "\n",
    "    a, b = (-jnp.inf - m_est) / m_err, (lim - m_est) / m_err\n",
    "    logpdf = truncnorm.logpdf(m_det, a, b, loc=m_est, scale=m_err)\n",
    "\n",
    "    return logpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data a jnp array\n",
    "for filt in filters:\n",
    "    data[filt] = jnp.asarray(data[filt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO change this: we are toying with the compute LC function\n",
    "\n",
    "# calc_lc_function = calc_lc_given_params_jit\n",
    "calc_lc_function = calc_lc_given_params\n",
    "\n",
    "def get_chisq_filt(mag_abs, \n",
    "                   sample_times,\n",
    "                   data_time, \n",
    "                   data_mag, \n",
    "                   data_sigma,\n",
    "                   t0: float = 0.0,\n",
    "                   error_budget: float = 1.0,\n",
    "                   luminosity_distance = 44.0):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function taken from nmma/em/likelihood.py and adapted to this case here\n",
    "    \n",
    "    This is a piece of the log likelihood function, which is the sum of the chisquare for a single filter, to decompose the likelihood calculation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO non-zero time\n",
    "    # TODO include non-trivial error budget\n",
    "\n",
    "    # Calculate apparent magnitude\n",
    "    mag_app = mag_abs + 5.0 * jnp.log10(\n",
    "        luminosity_distance * 1e6 / 10.0\n",
    "    )\n",
    "    \n",
    "    # Limit to finite magnitudes\n",
    "    # TODO implement check for finite\n",
    "    sample_times_used = sample_times\n",
    "    mag_app_used = mag_app\n",
    "    \n",
    "    # Add the error budget to the sigma\n",
    "    data_sigma = jnp.sqrt(data_sigma ** 2 + error_budget ** 2)\n",
    "\n",
    "    # Evaluate the light curve magnitude at the data points\n",
    "    mag_est = jnp.interp(data_time, sample_times_used + t0, mag_app_used, left=\"extrapolate\", right=\"extrapolate\")\n",
    "\n",
    "    # TODO get detection limit?\n",
    "    detection_limit = jnp.inf\n",
    "    minus_chisquare = jnp.sum(\n",
    "        truncated_gaussian(\n",
    "            data_mag,\n",
    "            data_sigma,\n",
    "            mag_est,\n",
    "            detection_limit,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return minus_chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(parameters, luminosity_distance = 44.0):\n",
    "    \"\"\"\n",
    "    Function taken from nmma/em/likelihood.py and adapted to this case here\n",
    "    \n",
    "    TODO: \n",
    "    - separate LC params from parameters?\n",
    "    - add error budget\n",
    "    - add timeshift\n",
    "    - add luminosity distance\n",
    "    - this is assuming all data are \"finite\" and the LC is finite. Not checking this here since breaks JAX jit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate the light curve\n",
    "    _, _, mag_abs = calc_lc_function(parameters)\n",
    "    \n",
    "    minus_chisquare_total = 0.0\n",
    "    for filt in filters:\n",
    "        # Decompose the data of this filter\n",
    "        data_time, data_mag, data_sigma  = copy.deepcopy(data[filt]).T\n",
    "        mag_abs_filt = mag_abs[filt]\n",
    "        # Compute the chi squared for this filter\n",
    "        chisq_filt = get_chisq_filt(mag_abs_filt, sample_times, data_time, data_mag, data_sigma, luminosity_distance = luminosity_distance)\n",
    "        minus_chisquare_total += chisq_filt\n",
    "\n",
    "    log_prob = minus_chisquare_total\n",
    "\n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: check if gradient on truncated gaussian gives NaNs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some dummy values for the parameters\n",
    "filt = filters[0]\n",
    "data_mag = copy.deepcopy(data[filt][:, 1])\n",
    "data_sigma = copy.deepcopy(data[filt][:, 2])\n",
    "error_budget = 1.0\n",
    "detection_limit = jnp.inf\n",
    "data_sigma = jnp.sqrt(data_sigma ** 2 + error_budget ** 2)\n",
    "\n",
    "# dummy estimated magnitudes\n",
    "mag_est = data_mag + 0.1\n",
    "\n",
    "def test_truncated_gaussian(data_mag,\n",
    "            data_sigma,\n",
    "            mag_est,\n",
    "            detection_limit):\n",
    "    \"\"\"\n",
    "    Test the truncated gaussian function\n",
    "    \"\"\"\n",
    "\n",
    "    return jnp.sum(\n",
    "        truncated_gaussian(\n",
    "            data_mag,\n",
    "            data_sigma,\n",
    "            mag_est,\n",
    "            detection_limit,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.304478773133997\n",
      "[0.09996002 0.09936407 0.09858044 0.09984026 0.09719118 0.09577627\n",
      " 0.09880447 0.0975039  0.0975039  0.09538344 0.07871537 0.08963786\n",
      " 0.09615385]\n"
     ]
    }
   ],
   "source": [
    "print(test_truncated_gaussian(data_mag, data_sigma, mag_est, detection_limit))\n",
    "print(jax.grad(test_truncated_gaussian)(data_mag, data_sigma, mag_est, detection_limit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking likelihood computation and gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jax.make_jaxpr(log_likelihood)(test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jax.make_jaxpr(jax.grad(log_likelihood))(test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for random params\n",
      "-87354960718.77606\n"
     ]
    }
   ],
   "source": [
    "# print(parameters)\n",
    "# nmma_params = jnp.array([-2.22, 0.12, 0.3, -1.15, 0.03, 25.84])\n",
    "\n",
    "print(\"Test for random params\")\n",
    "test_logL = log_likelihood(test_params)\n",
    "print(test_logL)\n",
    "\n",
    "# print(\"Test for params from NMMA\")\n",
    "# test_logL = log_likelihood(nmma_params)\n",
    "# print(nmma_logL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan nan]\n"
     ]
    }
   ],
   "source": [
    "test_dv_logL = jax.grad(log_likelihood)(test_params)\n",
    "print(test_dv_logL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior(theta, data):\n",
    "    # NOTE: the data argument is unused?\n",
    "    prior = top_hat(theta)\n",
    "    return log_likelihood(theta) + prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial position of chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chains = 100\n",
    "\n",
    "rng_key_set = initialize_rng_keys(n_chains, seed=42)\n",
    "\n",
    "initial_position = jax.random.uniform(rng_key_set[0], shape=(int(n_chains), n_dim)) * 1\n",
    "for i in range(n_dim):\n",
    "    initial_position = initial_position.at[:,i].set(initial_position[:,i]*(prior_range[i,1]-prior_range[i,0])+prior_range[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing sampler class\n"
     ]
    }
   ],
   "source": [
    "model = MaskedCouplingRQSpline(n_dim, 10, [128,128], 8, jax.random.PRNGKey(42))\n",
    "\n",
    "print(\"Initializing sampler class\")\n",
    "\n",
    "mass_matrix = jnp.eye(n_dim)\n",
    "eps = 1e-3\n",
    "# TODO any tuning to be done here?\n",
    "posterior = posterior\n",
    "\n",
    "local_sampler_arg = {\"step_size\": mass_matrix * eps}\n",
    "use_jit = True\n",
    "# local_sampler = MALA(posterior, use_jit, local_sampler_arg) ## TODO derivative is broken so MALA is broken\n",
    "local_sampler = GaussianRandomWalk(posterior, use_jit, {\"step_size\": eps})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_sampler = Sampler(\n",
    "    n_dim,\n",
    "    rng_key_set,\n",
    "    None,\n",
    "    local_sampler,\n",
    "    model,\n",
    "    n_loop_training=50,\n",
    "    n_loop_production=10,\n",
    "    n_local_steps=20,\n",
    "    n_global_steps=20,\n",
    "    n_chains=n_chains,\n",
    "    n_epochs=100,\n",
    "    learning_rate=0.001,\n",
    "    max_samples=50000,\n",
    "    momentum=0.9,\n",
    "    batch_size=50000,\n",
    "    use_global=True,\n",
    "    keep_quantile=0.0,\n",
    "    train_thinning=1,\n",
    "    output_thinning=1,    \n",
    "    local_sampler_arg=local_sampler_arg,\n",
    "    outdir_name=\"./outdir/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: without jitting, we get more print statements (as expected since that is a byproduct of the function), and the training loop takes around 4 minutes, production loop around 2 mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No autotune found, use input sampler_params\n",
      "Training normalizing flow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning global sampler:   0%|          | 0/50 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nf_sampler\u001b[39m.\u001b[39;49msample(initial_position, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/flowMC/src/flowMC/sampler/Sampler.py:109\u001b[0m, in \u001b[0;36mSampler.sample\u001b[0;34m(self, initial_position, data)\u001b[0m\n\u001b[1;32m    106\u001b[0m     last_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpretraining_run(last_step, data)\n\u001b[1;32m    108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_global \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_loop_training \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 109\u001b[0m     last_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mglobal_sampler_tuning(last_step, data)\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_loop_production \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    112\u001b[0m     last_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproduction_run(last_step, data)\n",
      "File \u001b[0;32m~/flowMC/src/flowMC/sampler/Sampler.py:309\u001b[0m, in \u001b[0;36mSampler.global_sampler_tuning\u001b[0;34m(self, initial_position, data)\u001b[0m\n\u001b[1;32m    304\u001b[0m last_step \u001b[39m=\u001b[39m initial_position\n\u001b[1;32m    305\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m tqdm(\n\u001b[1;32m    306\u001b[0m     \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_loop_training),\n\u001b[1;32m    307\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTuning global sampler\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    308\u001b[0m ):\n\u001b[0;32m--> 309\u001b[0m     last_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msampling_loop(last_step, data, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    310\u001b[0m \u001b[39mreturn\u001b[39;00m last_step\n",
      "File \u001b[0;32m~/flowMC/src/flowMC/sampler/Sampler.py:139\u001b[0m, in \u001b[0;36mSampler.sampling_loop\u001b[0;34m(self, initial_position, data, training, pretraining)\u001b[0m\n\u001b[1;32m    136\u001b[0m     production \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39m# First run the local sampler\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrng_keys_mcmc, positions, log_prob, local_acceptance \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlocal_sampler\u001b[39m.\u001b[39;49msample(\n\u001b[1;32m    140\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrng_keys_mcmc,\n\u001b[1;32m    141\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_local_steps,\n\u001b[1;32m    142\u001b[0m     initial_position,\n\u001b[1;32m    143\u001b[0m     data,\n\u001b[1;32m    144\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    145\u001b[0m )\n\u001b[1;32m    147\u001b[0m \u001b[39m# Save local sampler states\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msummary[summary_mode][\u001b[39m\"\u001b[39m\u001b[39mchains\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    149\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msummary[summary_mode][\u001b[39m\"\u001b[39m\u001b[39mchains\u001b[39m\u001b[39m\"\u001b[39m], positions[:, ::\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_thinning], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    150\u001b[0m )\n",
      "File \u001b[0;32m~/flowMC/src/flowMC/sampler/Gaussian_random_walk.py:97\u001b[0m, in \u001b[0;36mGaussianRandomWalk.sample\u001b[0;34m(self, rng_key, n_steps, initial_position, data, verbose)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msample\u001b[39m(\n\u001b[1;32m     86\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     87\u001b[0m     rng_key: PRNGKeyArray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m     Int[Array, \u001b[39m\"\u001b[39m\u001b[39mn_chains n_steps 1\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     96\u001b[0m ]:\n\u001b[0;32m---> 97\u001b[0m     logp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogpdf_vmap(initial_position, data)\n\u001b[1;32m     98\u001b[0m     n_chains \u001b[39m=\u001b[39m rng_key\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     99\u001b[0m     acceptance \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mzeros((n_chains, n_steps))\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/nmma_gpu/lib/python3.10/site-packages/jax/_src/pjit.py:255\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39m@api_boundary\u001b[39m\n\u001b[1;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcache_miss\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 255\u001b[0m   outs, out_flat, out_tree, args_flat, jaxpr \u001b[39m=\u001b[39m _python_pjit_helper(\n\u001b[1;32m    256\u001b[0m       fun, infer_params_fn, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    257\u001b[0m   executable \u001b[39m=\u001b[39m _read_most_recent_pjit_call_executable(jaxpr)\n\u001b[1;32m    258\u001b[0m   fastpath_data \u001b[39m=\u001b[39m _get_fastpath_data(executable, out_tree, args_flat, out_flat)\n",
      "File \u001b[0;32m~/miniconda3/envs/nmma_gpu/lib/python3.10/site-packages/jax/_src/pjit.py:166\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[0;34m(fun, infer_params_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m   dispatch\u001b[39m.\u001b[39mcheck_arg(arg)\n\u001b[1;32m    165\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m   out_flat \u001b[39m=\u001b[39m pjit_p\u001b[39m.\u001b[39;49mbind(\u001b[39m*\u001b[39;49margs_flat, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    167\u001b[0m \u001b[39mexcept\u001b[39;00m pxla\u001b[39m.\u001b[39mDeviceAssignmentMismatchError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    168\u001b[0m   fails, \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39margs\n",
      "File \u001b[0;32m~/miniconda3/envs/nmma_gpu/lib/python3.10/site-packages/jax/_src/core.py:2682\u001b[0m, in \u001b[0;36mAxisPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m   2678\u001b[0m axis_main \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m((axis_frame(a)\u001b[39m.\u001b[39mmain_trace \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m used_axis_names(\u001b[39mself\u001b[39m, params)),\n\u001b[1;32m   2679\u001b[0m                 default\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m t: \u001b[39mgetattr\u001b[39m(t, \u001b[39m'\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m   2680\u001b[0m top_trace \u001b[39m=\u001b[39m (top_trace \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m axis_main \u001b[39mor\u001b[39;00m axis_main\u001b[39m.\u001b[39mlevel \u001b[39m<\u001b[39m top_trace\u001b[39m.\u001b[39mlevel\n\u001b[1;32m   2681\u001b[0m              \u001b[39melse\u001b[39;00m axis_main\u001b[39m.\u001b[39mwith_cur_sublevel())\n\u001b[0;32m-> 2682\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbind_with_trace(top_trace, args, params)\n",
      "File \u001b[0;32m~/miniconda3/envs/nmma_gpu/lib/python3.10/site-packages/jax/_src/core.py:405\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind_with_trace\u001b[39m(\u001b[39mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 405\u001b[0m   out \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39;49mprocess_primitive(\u001b[39mself\u001b[39;49m, \u001b[39mmap\u001b[39;49m(trace\u001b[39m.\u001b[39;49mfull_raise, args), params)\n\u001b[1;32m    406\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, out) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiple_results \u001b[39melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/nmma_gpu/lib/python3.10/site-packages/jax/_src/core.py:893\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_primitive\u001b[39m(\u001b[39mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 893\u001b[0m   \u001b[39mreturn\u001b[39;00m primitive\u001b[39m.\u001b[39;49mimpl(\u001b[39m*\u001b[39;49mtracers, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/miniconda3/envs/nmma_gpu/lib/python3.10/site-packages/jax/_src/pjit.py:1238\u001b[0m, in \u001b[0;36m_pjit_call_impl\u001b[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1235\u001b[0m donated_argnums \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i, d \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(donated_invars) \u001b[39mif\u001b[39;00m d]\n\u001b[1;32m   1236\u001b[0m has_explicit_sharding \u001b[39m=\u001b[39m _pjit_explicit_sharding(\n\u001b[1;32m   1237\u001b[0m     in_shardings, out_shardings, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 1238\u001b[0m \u001b[39mreturn\u001b[39;00m xc\u001b[39m.\u001b[39;49m_xla\u001b[39m.\u001b[39;49mpjit(name, f, call_impl_cache_miss, [], [], donated_argnums,\n\u001b[1;32m   1239\u001b[0m                     tree_util\u001b[39m.\u001b[39;49mdispatch_registry,\n\u001b[1;32m   1240\u001b[0m                     _get_cpp_global_cache(has_explicit_sharding))(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/nmma_gpu/lib/python3.10/site-packages/jax/_src/pjit.py:1222\u001b[0m, in \u001b[0;36m_pjit_call_impl.<locals>.call_impl_cache_miss\u001b[0;34m(*args_, **kwargs_)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_impl_cache_miss\u001b[39m(\u001b[39m*\u001b[39margs_, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs_):\n\u001b[0;32m-> 1222\u001b[0m   out_flat, compiled \u001b[39m=\u001b[39m _pjit_call_impl_python(\n\u001b[1;32m   1223\u001b[0m       \u001b[39m*\u001b[39;49margs, jaxpr\u001b[39m=\u001b[39;49mjaxpr, in_shardings\u001b[39m=\u001b[39;49min_shardings,\n\u001b[1;32m   1224\u001b[0m       out_shardings\u001b[39m=\u001b[39;49mout_shardings, resource_env\u001b[39m=\u001b[39;49mresource_env,\n\u001b[1;32m   1225\u001b[0m       donated_invars\u001b[39m=\u001b[39;49mdonated_invars, name\u001b[39m=\u001b[39;49mname, keep_unused\u001b[39m=\u001b[39;49mkeep_unused,\n\u001b[1;32m   1226\u001b[0m       inline\u001b[39m=\u001b[39;49minline)\n\u001b[1;32m   1227\u001b[0m   fastpath_data \u001b[39m=\u001b[39m _get_fastpath_data(\n\u001b[1;32m   1228\u001b[0m       compiled, tree_structure(out_flat), args, out_flat)\n\u001b[1;32m   1229\u001b[0m   \u001b[39mreturn\u001b[39;00m out_flat, fastpath_data\n",
      "File \u001b[0;32m~/miniconda3/envs/nmma_gpu/lib/python3.10/site-packages/jax/_src/pjit.py:1158\u001b[0m, in \u001b[0;36m_pjit_call_impl_python\u001b[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[39mglobal\u001b[39;00m _most_recent_pjit_call_executable\n\u001b[1;32m   1151\u001b[0m in_shardings \u001b[39m=\u001b[39m _resolve_in_shardings(\n\u001b[1;32m   1152\u001b[0m     args, in_shardings, out_shardings,\n\u001b[1;32m   1153\u001b[0m     resource_env\u001b[39m.\u001b[39mphysical_mesh \u001b[39mif\u001b[39;00m resource_env \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1155\u001b[0m compiled \u001b[39m=\u001b[39m _pjit_lower(\n\u001b[1;32m   1156\u001b[0m     jaxpr, in_shardings, out_shardings, resource_env,\n\u001b[1;32m   1157\u001b[0m     donated_invars, name, keep_unused, inline,\n\u001b[0;32m-> 1158\u001b[0m     lowering_parameters\u001b[39m=\u001b[39;49mmlir\u001b[39m.\u001b[39;49mLoweringParameters())\u001b[39m.\u001b[39;49mcompile()\n\u001b[1;32m   1159\u001b[0m _most_recent_pjit_call_executable\u001b[39m.\u001b[39mweak_key_dict[jaxpr] \u001b[39m=\u001b[39m compiled\n\u001b[1;32m   1160\u001b[0m \u001b[39m# This check is expensive so only do it if enable_checks is on.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nmma_gpu/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:2208\u001b[0m, in \u001b[0;36mMeshComputation.compile\u001b[0;34m(self, compiler_options)\u001b[0m\n\u001b[1;32m   2206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompile\u001b[39m(\u001b[39mself\u001b[39m, compiler_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m MeshExecutable:\n\u001b[1;32m   2207\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executable \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m compiler_options \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2208\u001b[0m     executable \u001b[39m=\u001b[39m UnloadedMeshExecutable\u001b[39m.\u001b[39;49mfrom_hlo(\n\u001b[1;32m   2209\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_hlo, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompile_args,\n\u001b[1;32m   2210\u001b[0m         compiler_options\u001b[39m=\u001b[39;49mcompiler_options)\n\u001b[1;32m   2211\u001b[0m     \u001b[39mif\u001b[39;00m compiler_options \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2212\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executable \u001b[39m=\u001b[39m executable\n",
      "File \u001b[0;32m~/miniconda3/envs/nmma_gpu/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:2648\u001b[0m, in \u001b[0;36mUnloadedMeshExecutable.from_hlo\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2645\u001b[0m       mesh \u001b[39m=\u001b[39m i\u001b[39m.\u001b[39mmesh  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m   2646\u001b[0m       \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 2648\u001b[0m xla_executable, compile_options \u001b[39m=\u001b[39m _cached_compilation(\n\u001b[1;32m   2649\u001b[0m     hlo, name, mesh, spmd_lowering,\n\u001b[1;32m   2650\u001b[0m     tuple_args, auto_spmd_lowering, allow_prop_to_outputs,\n\u001b[1;32m   2651\u001b[0m     \u001b[39mtuple\u001b[39;49m(host_callbacks), backend, da, pmap_nreps,\n\u001b[1;32m   2652\u001b[0m     compiler_options_keys, compiler_options_values)\n\u001b[1;32m   2654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(backend, \u001b[39m\"\u001b[39m\u001b[39mcompile_replicated\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   2655\u001b[0m   semantics_in_shardings \u001b[39m=\u001b[39m SemanticallyEqualShardings(in_shardings)  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nmma_gpu/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:2517\u001b[0m, in \u001b[0;36m_cached_compilation\u001b[0;34m(computation, name, mesh, spmd_lowering, tuple_args, auto_spmd_lowering, _allow_propagation_to_outputs, host_callbacks, backend, da, pmap_nreps, compiler_options_keys, compiler_options_values)\u001b[0m\n\u001b[1;32m   2512\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m, compile_options\n\u001b[1;32m   2514\u001b[0m \u001b[39mwith\u001b[39;00m dispatch\u001b[39m.\u001b[39mlog_elapsed_time(\n\u001b[1;32m   2515\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mFinished XLA compilation of \u001b[39m\u001b[39m{fun_name}\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m{elapsed_time}\u001b[39;00m\u001b[39m sec\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2516\u001b[0m     fun_name\u001b[39m=\u001b[39mname, event\u001b[39m=\u001b[39mdispatch\u001b[39m.\u001b[39mBACKEND_COMPILE_EVENT):\n\u001b[0;32m-> 2517\u001b[0m   xla_executable \u001b[39m=\u001b[39m compiler\u001b[39m.\u001b[39;49mcompile_or_get_cached(\n\u001b[1;32m   2518\u001b[0m       backend, computation, dev, compile_options, host_callbacks)\n\u001b[1;32m   2519\u001b[0m \u001b[39mreturn\u001b[39;00m xla_executable, compile_options\n",
      "File \u001b[0;32m~/miniconda3/envs/nmma_gpu/lib/python3.10/site-packages/jax/_src/compiler.py:350\u001b[0m, in \u001b[0;36mcompile_or_get_cached\u001b[0;34m(backend, computation, devices, compile_options, host_callbacks)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m   start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 350\u001b[0m   executable \u001b[39m=\u001b[39m backend_compile(backend, computation,\n\u001b[1;32m    351\u001b[0m                               compile_options, host_callbacks)\n\u001b[1;32m    352\u001b[0m   compile_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m    353\u001b[0m   _cache_write(cache_key, compile_time, module_name, backend, executable,\n\u001b[1;32m    354\u001b[0m                host_callbacks)\n",
      "File \u001b[0;32m~/miniconda3/envs/nmma_gpu/lib/python3.10/site-packages/jax/_src/profiler.py:334\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    333\u001b[0m   \u001b[39mwith\u001b[39;00m TraceAnnotation(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 334\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    335\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/miniconda3/envs/nmma_gpu/lib/python3.10/site-packages/jax/_src/compiler.py:261\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39mcompile(built_c, compile_options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m    257\u001b[0m                          host_callbacks\u001b[39m=\u001b[39mhost_callbacks)\n\u001b[1;32m    258\u001b[0m \u001b[39m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mcompile(built_c, compile_options\u001b[39m=\u001b[39;49moptions)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# nf_sampler.sample(initial_position, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating plots\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nf_sampler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCreating plots\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m nf_sampler\u001b[39m.\u001b[39mplot_summary(\u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m nf_sampler\u001b[39m.\u001b[39mplot_summary(\u001b[39m\"\u001b[39m\u001b[39mproduction\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nf_sampler' is not defined"
     ]
    }
   ],
   "source": [
    "# print(\"Creating plots\")\n",
    "# nf_sampler.plot_summary(\"training\")\n",
    "# nf_sampler.plot_summary(\"production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO, can we do inference with Numpyro?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Install numpyro and make sure it does not break the conda env again\n",
    "\n",
    "**TODO**: Get likelihood etc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpyro\n",
    "# from numpyro.diagnostics import hpdi, summary\n",
    "# import numpyro.distributions as dist\n",
    "# from numpyro import handlers\n",
    "# from numpyro.infer import MCMC, NUTS\n",
    "# numpyro.set_platform(\"gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_inference(\n",
    "#     model, num_warmup=1000, num_samples=1000, max_tree_depth=10, dense_mass=False\n",
    "# ):\n",
    "#     kernel = NUTS(model, max_tree_depth=max_tree_depth, dense_mass=dense_mass)\n",
    "#     mcmc = MCMC(\n",
    "#         kernel,\n",
    "#         num_warmup=num_warmup,\n",
    "#         num_samples=num_samples,\n",
    "#         num_chains=1,\n",
    "#         progress_bar=False,\n",
    "#     )\n",
    "#     mcmc.run(jax.random.PRNGKey(0))\n",
    "#     summary_dict = summary(mcmc.get_samples(), group_by_chain=False)\n",
    "\n",
    "#     # print the largest r_hat for each variable\n",
    "#     for k, v in summary_dict.items():\n",
    "#         spaces = \" \" * max(12 - len(k), 0)\n",
    "#         print(\"[{}] {} \\t max r_hat: {:.4f}\".format(k, spaces, np.max(v[\"r_hat\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmma_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
