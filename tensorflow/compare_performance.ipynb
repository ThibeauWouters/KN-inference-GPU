{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing KN surrogate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abstract:** Here we compare the MSE of the surrogate models between, e.g. the existing Tensorflow model on Zenodo vs a new, deep network as surrogate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Install wrapt_timeout_decorator if you want timeout simulations.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from nmma.em.training import SVDTrainingModel\n",
    "import nmma as nmma\n",
    "import time\n",
    "import arviz\n",
    "\n",
    "params = {\"axes.grid\": True,\n",
    "        \"text.usetex\" : True,\n",
    "        \"font.family\" : \"serif\",\n",
    "        \"ytick.color\" : \"black\",\n",
    "        \"xtick.color\" : \"black\",\n",
    "        \"axes.labelcolor\" : \"black\",\n",
    "        \"axes.edgecolor\" : \"black\",\n",
    "        \"font.serif\" : [\"Computer Modern Serif\"],\n",
    "        \"xtick.labelsize\": 16,\n",
    "        \"ytick.labelsize\": 16,\n",
    "        \"axes.labelsize\": 16,\n",
    "        \"legend.fontsize\": 16,\n",
    "        \"legend.title_fontsize\": 16,\n",
    "        \"figure.titlesize\": 16}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "from nmma.em.io import read_photometry_files\n",
    "from nmma.em.utils import interpolate_nans\n",
    "\n",
    "import inspect \n",
    "import nmma.em.model_parameters as model_parameters\n",
    "\n",
    "MODEL_FUNCTIONS = {\n",
    "    k: v for k, v in model_parameters.__dict__.items() if inspect.isfunction(v)\n",
    "}\n",
    "\n",
    "model_name = \"Bu2022Ye\"\n",
    "model_function = MODEL_FUNCTIONS[model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1596 lightcurves for this model.\n",
      "Reading lightcurves and interpolating NaNs...\n",
      "Reading lightcurves and interpolating NaNs... DONE\n",
      "Filters:\n",
      "['sdss__g', 'sdss__i', 'sdss__r']\n",
      "Genrating training data...\n",
      "Genrating training data... DONE\n"
     ]
    }
   ],
   "source": [
    "# Choose model and set location of the kilonova lightcurves\n",
    "bulla_2022_dir = \"/home/urash/twouters/KN_Lightcurves/lightcurves/lcs_bulla_2022\"\n",
    "bulla_2019_dir = \"/home/urash/twouters/KN_Lightcurves/lightcurves/lcs_bulla_2019\"\n",
    "\n",
    "# Choose the model here\n",
    "# model_name = \"Bu2022Ye\"\n",
    "model_name = \"Bu2019lm\"\n",
    "model_function = MODEL_FUNCTIONS[model_name]\n",
    "\n",
    "# Set the location of the lightcurves and outdir based on chosen model\n",
    "if model_name == \"Bu2022Ye\":\n",
    "    lcs_dir = bulla_2022_dir\n",
    "    \n",
    "elif model_name == \"Bu2019lm\":\n",
    "    lcs_dir = bulla_2019_dir\n",
    "\n",
    "svd_path = f\"/home/urash/twouters/new_nmma_models/\"\n",
    "old_svd_path = f\"/home/urash/twouters/nmma_models/\"\n",
    "\n",
    "# Process the KN lightcurves\n",
    "filenames = os.listdir(lcs_dir)\n",
    "full_filenames = [os.path.join(lcs_dir, f) for f in filenames]\n",
    "print(f\"There are {len(full_filenames)} lightcurves for this model.\")\n",
    "\n",
    "print(\"Reading lightcurves and interpolating NaNs...\")\n",
    "data = read_photometry_files(full_filenames)\n",
    "data = interpolate_nans(data)\n",
    "keys = list(data.keys())\n",
    "filts = sorted(list(set(data[keys[0]].keys()) - {\"t\"}))\n",
    "\n",
    "print(\"Reading lightcurves and interpolating NaNs... DONE\")\n",
    "\n",
    "# Limit to the filters of interest for the KN event that Peter is interested in:\n",
    "if model_name == \"Bu2022Ye\":\n",
    "    filts = [\"ztfg\", \"ztfi\", \"ztfr\"] # limited for now for Peter's KN event\n",
    "else:\n",
    "    zenodo_filts  = [\"ztfg\", \"ztfi\", \"ztfr\"]\n",
    "    filts = ['sdss__g', 'sdss__i', 'sdss__r'] # NOTE we ignore , 'sdss__u', 'sdss__z' for the comparison with the zenodo data\n",
    "    \n",
    "print(\"Filters:\")\n",
    "print(filts)\n",
    "\n",
    "# Get the time array\n",
    "dat = pd.read_csv(full_filenames[0], delimiter=\" \", escapechar='#')\n",
    "dat = dat.rename(columns={\" t[days]\": \"t\"})\n",
    "t = dat[\"t\"].values\n",
    "\n",
    "print(\"Genrating training data...\")\n",
    "training_data, parameters = model_function(data)\n",
    "print(\"Genrating training data... DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bu2019lm'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading new LC model...\n",
      "Loaded filter sdss__g\n",
      "Loaded filter sdss__i\n",
      "Loaded filter sdss__r\n",
      "Loading new LC model... DONE\n",
      "Loading old LC model...\n",
      "Loaded filter ztfg\n",
      "Loaded filter ztfi\n",
      "Loaded filter ztfr\n",
      "Loading old LC model... DONE\n"
     ]
    }
   ],
   "source": [
    "from nmma.em.model import SVDLightCurveModel\n",
    "\n",
    "print(\"Loading new LC model...\")\n",
    "new_lc_model = SVDLightCurveModel(\n",
    "        model_name,\n",
    "        t,\n",
    "        svd_path=svd_path,\n",
    "        parameter_conversion=None,\n",
    "        mag_ncoeff=10,\n",
    "        lbol_ncoeff=None,\n",
    "        interpolation_type=\"tensorflow\",\n",
    "        model_parameters=None,\n",
    "        filters=filts,\n",
    "        local_only=True\n",
    ")\n",
    "print(\"Loading new LC model... DONE\")\n",
    "\n",
    "if model_name == \"Bu2022Ye\":\n",
    "        old_model_name = model_name\n",
    "        old_filts = filts # use the same filters\n",
    "else:\n",
    "        old_model_name = model_name \n",
    "        old_filts = zenodo_filts # load the zenodo filters instead\n",
    "\n",
    "print(\"Loading old LC model...\")\n",
    "old_lc_model = SVDLightCurveModel(\n",
    "        model_name,\n",
    "        t,\n",
    "        svd_path=old_svd_path,\n",
    "        parameter_conversion=None,\n",
    "        mag_ncoeff=10,\n",
    "        lbol_ncoeff=None,\n",
    "        interpolation_type=\"tensorflow\",\n",
    "        model_parameters=None,\n",
    "        filters=old_filts,\n",
    "        local_only=True\n",
    ")\n",
    "print(\"Loading old LC model... DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the input and output pairs of lightcurve grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_values(training_data: dict, parameters: list) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    From a dictionary of training data, extract the input values for the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    input_values = []\n",
    "    \n",
    "    for key in training_data.keys():\n",
    "        data = training_data[key]\n",
    "        input_values.append([data[param] for param in parameters])\n",
    "    \n",
    "    return np.array(input_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_values(training_data: dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    From a dictionary of training data, extract the output values for the model.\n",
    "    \"\"\"\n",
    "    if \"data\" in training_data[keys[0]].keys():\n",
    "        # This is the version that was in use for NMMA-GPU\n",
    "        output_values = [training_data[key][\"data\"] for key in training_data.keys()]\n",
    "    else:\n",
    "        # This is the version for NMMA CPU, 12/12/2023\n",
    "        output_values = []\n",
    "        for key in training_data.keys():\n",
    "            data = training_data[key]\n",
    "            new_list = [data[f] for f in filts]\n",
    "            output_values.append(new_list)\n",
    "    \n",
    "    return np.array(output_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['log10_mej_dyn', 'vej_dyn', 'Yedyn', 'log10_mej_wind', 'vej_wind', 'KNtheta', 't', 'bessellux', 'bessellb', 'bessellv', 'bessellr', 'besselli', 'sdssu', 'ps1__g', 'ps1__r', 'ps1__i', 'ps1__z', 'ps1__y', 'uvot__b', 'uvot__u', 'uvot__uvm2', 'uvot__uvw1', 'uvot__uvw2', 'uvot__v', 'uvot__white', 'atlasc', 'atlaso', '2massj', '2massh', '2massks', 'ztfg', 'ztfr', 'ztfi'])\n"
     ]
    }
   ],
   "source": [
    "# Sanity check:\n",
    "keys = list(training_data.keys())\n",
    "example = training_data[keys[0]]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = get_input_values(training_data, parameters)\n",
    "output_values = get_output_values(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7700, 6)\n",
      "(7700, 3, 100)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(input_values))\n",
    "print(np.shape(output_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "# Select a random subset of indices for the input values\n",
    "idx_list = np.random.choice(len(input_values), N, replace=False)\n",
    "sampled_input_values = input_values[idx_list]\n",
    "sampled_output_values = output_values[idx_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get both outputs flax output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing all the lightcurves for a subset of 1000 lightcurves took 10.635529041290283 seconds for both new and old model.\n"
     ]
    }
   ],
   "source": [
    "# For this list, we compute the LCs using the flax model\n",
    "flax_output = []\n",
    "start = time.time()\n",
    "\n",
    "old_lc_model_output = []\n",
    "new_lc_model_output = []\n",
    "\n",
    "for i in range(len(sampled_input_values)):\n",
    "    ### OLD model\n",
    "    # Compute the lightcurve\n",
    "    _, _, mag = nmma.em.utils.calc_lc(t,\n",
    "                                sampled_input_values[i], \n",
    "                                svd_mag_model = old_lc_model.svd_mag_model, \n",
    "                                interpolation_type=\"tensorflow\", \n",
    "                                filters = old_filts, \n",
    "                                mag_ncoeff = 10\n",
    "                                )\n",
    "    # Convert this dictionary to values of the LCs\n",
    "    mag = mag.values()\n",
    "    mag = np.array(list(mag))\n",
    "    old_lc_model_output.append(mag)\n",
    "    \n",
    "    ### NEW model\n",
    "    # Compute the lightcurve\n",
    "    _, _, mag = nmma.em.utils.calc_lc(t,\n",
    "                                sampled_input_values[i], \n",
    "                                svd_mag_model = new_lc_model.svd_mag_model, \n",
    "                                interpolation_type=\"tensorflow\", \n",
    "                                filters = filts, \n",
    "                                mag_ncoeff = 10\n",
    "                                )\n",
    "    # Convert this dictionary to values of the LCs\n",
    "    mag = mag.values()\n",
    "    mag = np.array(list(mag))\n",
    "    new_lc_model_output.append(mag)\n",
    "end = time.time()\n",
    "print(f\"Computing all the lightcurves for a subset of {N} lightcurves took {end-start} seconds for both new and old model.\")\n",
    "\n",
    "# Convert to np arrays\n",
    "old_lc_model_output = np.array(old_lc_model_output)\n",
    "new_lc_model_output = np.array(new_lc_model_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare MSE or MAE values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Best to compare this as a distribution, and perhaps best to consider MAE, or some self-defined loss function or error function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred, axis=None):\n",
    "    return np.mean((y_true - y_pred)**2, axis=axis)\n",
    "\n",
    "def se(y_true, y_pred):\n",
    "    return (y_true - y_pred)**2\n",
    "\n",
    "def mae(y_true, y_pred, axis=None):\n",
    "    return np.mean(np.abs(y_true - y_pred), axis=axis)\n",
    "\n",
    "def ae(y_true, y_pred):\n",
    "    return np.abs(y_true - y_pred)\n",
    "\n",
    "def my_format(low: float, med: float, high: float, nb: int = 3) -> str:\n",
    "    med = np.round(med, nb)\n",
    "    low = med - low\n",
    "    low = np.round(low, nb)\n",
    "    high = high - med\n",
    "    high = np.round(high, nb)\n",
    "    \n",
    "    return f\"{med} - {low} + {high}\"\n",
    "\n",
    "# # TODO with arviz summarize the errors\n",
    "# def summarize_data(values: np.array, percentile: float = 0.95) -> None:\n",
    "    \n",
    "#     med = np.median(values)\n",
    "#     result = arviz.hdi(values, hdi_prob = percentile)\n",
    "    \n",
    "#     print(my_format(low, med, high))\n",
    "    \n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MSE for old model...\n",
      "ztfg: 2.52212\n",
      "ztfi: 1.80887\n",
      "ztfr: 1.08441\n",
      "Computing MSE for new model...\n",
      "ztfg: 2.16946\n",
      "ztfi: 1.48286\n",
      "ztfr: 0.82267\n",
      "Computing MAE for old model...\n",
      "ztfg: 0.98304\n",
      "ztfi: 0.87592\n",
      "ztfr: 0.72222\n",
      "Computing MAE for new model...\n",
      "ztfg: 0.89032\n",
      "ztfi: 0.76405\n",
      "ztfr: 0.60898\n"
     ]
    }
   ],
   "source": [
    "# which_dataset = flax_output\n",
    "# which_error = mae\n",
    "nb_round = 5\n",
    "for error_fn, name in zip([mse, mae], [\"MSE\", \"MAE\"]):\n",
    "    for dataset, dataset_name in zip([old_lc_model_output, new_lc_model_output], [\"old\", \"new\"]):\n",
    "        # diffs = se(dataset, sampled_output_values)\n",
    "        print(f\"Computing {name} for {dataset_name} model...\")\n",
    "        axis = 0\n",
    "        mse_values = error_fn(dataset, sampled_output_values, axis=axis)\n",
    "        mse_values = np.mean(mse_values, axis=0)\n",
    "        for f, val in zip(filts, mse_values):\n",
    "            print(f\"{f}: {np.round(val, nb_round)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
